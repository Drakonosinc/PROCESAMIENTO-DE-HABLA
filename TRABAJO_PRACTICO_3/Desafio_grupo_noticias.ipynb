{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicios Resueltos\n",
        "# Esteban Matias Cancino"
      ],
      "metadata": {
        "id": "zrS2LTv3Q_dI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq6j8LsYq1Dr"
      },
      "source": [
        "### Vectorización de texto y modelo de clasificación Naïve Bayes con el dataset 20 newsgroups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7cXR6CI30ry"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# 20newsgroups por ser un dataset clásico de NLP ya viene incluido y formateado\n",
        "# en sklearn\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD-pVDWV_rQc"
      },
      "source": [
        "## Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ech9qJaUo9vK"
      },
      "outputs": [],
      "source": [
        "# cargamos los datos (ya separados de forma predeterminada en train y test)\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxjSI7su_uWI"
      },
      "source": [
        "## Vectorización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-94VP0QYCzDn"
      },
      "outputs": [],
      "source": [
        "# instanciamos un vectorizador\n",
        "# ver diferentes parámetros de instanciación en la documentación de sklearn\n",
        "tfidfvect = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftPlyanuak8n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "e0f39dc1-1deb-4d9f-c029-bed2f5970813"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"A fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll. Thanks.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# en el atributo `data` accedemos al texto\n",
        "newsgroups_train.data[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zxcXV6aC_oL"
      },
      "outputs": [],
      "source": [
        "# con la interfaz habitual de sklearn podemos fitear el vectorizador\n",
        "# (obtener el vocabulario y calcular el vector IDF)\n",
        "# y transformar directamente los datos\n",
        "X_train = tfidfvect.fit_transform(newsgroups_train.data)\n",
        "# `X_train` la podemos denominar como la matriz documento-término"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Sv7TXbda41-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0131c3d3-687a-4be5-c1cf-467b812e51db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'>\n",
            "shape: (11314, 101631)\n",
            "cantidad de documentos: 11314\n",
            "tamaño del vocabulario (dimensionalidad de los vectores): 101631\n"
          ]
        }
      ],
      "source": [
        "# recordar que las vectorizaciones por conteos son esparsas\n",
        "# por ello sklearn convenientemente devuelve los vectores de documentos\n",
        "# como matrices esparsas\n",
        "print(type(X_train))\n",
        "print(f'shape: {X_train.shape}')\n",
        "print(f'cantidad de documentos: {X_train.shape[0]}')\n",
        "print(f'tamaño del vocabulario (dimensionalidad de los vectores): {X_train.shape[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgydNTZ2pAgR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99cc2e2e-a3f2-44bc-cd55-8a4d81a7ea6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25775"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# una vez ajustado el vectorizador, podemos acceder a atributos como el vocabulario\n",
        "# aprendido. Es un diccionario que va de términos a índices.\n",
        "# El índice es la posición en el vector de documento.\n",
        "tfidfvect.vocabulary_['car']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnTSZuvyrTcP"
      },
      "outputs": [],
      "source": [
        "# es muy útil tener el diccionario opuesto que va de índices a términos\n",
        "idx2word = {v: k for k,v in tfidfvect.vocabulary_.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swa-AgWrMSHM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f03ce33f-9ee0-480c-b79f-76f476e29554"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# en `y_train` guardamos los targets que son enteros\n",
        "y_train = newsgroups_train.target\n",
        "y_train[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "je5kxvQMDLvf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e159210-aac7-464b-ff4c-494533786986"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clases [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# hay 20 clases correspondientes a los 20 grupos de noticias\n",
        "print(f'clases {np.unique(newsgroups_test.target)}')\n",
        "newsgroups_test.target_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXCICFSd_y90"
      },
      "source": [
        "## Similaridad de documentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pki_olShnyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59ff5a9e-5ce9-42ee-f02c-81080dc27823"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "/(hudson)\n",
            "/If someone inflicts pain on themselves, whether they enjoy it or not, they\n",
            "/are hurting themselves.  They may be permanently damaging their body.\n",
            "\n",
            "That is true.  It is also none of your business.  \n",
            "\n",
            "Some people may also reason that by reading the bible and being a Xtian\n",
            "you are permanently damaging your brain.  By your logic, it would be OK\n",
            "for them to come into your home, take away your bible, and send you off\n",
            "to \"re-education camps\" to save your mind from ruin.  Are you ready for\n",
            "that?  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "/(hudson)\n",
            "/And why is there nothing wrong with it?  Because you say so?  Who gave you\n",
            "/the authority to say that, and set the standard for morality?\n",
            "\n",
            "Why?\n",
            "\n",
            "Because: \n",
            "I am a living, thinking person able to make choices for myself.\n",
            "I do not \"need\" you to show me what you think is the way; I have observed\n",
            "too many errors in your thinking already to trust you to make up the\n",
            "rules for me.\n",
            "\n",
            "Because:\n",
            "I set the standard for my *own* morality, and I permit you to do \n",
            "the same for yourself.  I also do not try to force you to accept my rules.\n",
            "\n",
            "Because:\n",
            "Simply because you don't like what other people are doing doesn't give you\n",
            "the right to stop it, Hudson.  We are all aware that you would like for \n",
            "everyone to be like you.  However, it is obnoxious, arrogant thinking like \n",
            "yours, the \"I-know-I'm-morally-right-so-I-can-force-it-on-you\" bullshit \n",
            "that has brought us religious wars, pogroms against Jews, gay-bashing,\n",
            "and other atrocities by other people who, like you, \"knew\" they were\n",
            "morally right.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "(me)\n",
            "\n",
            "/(hudson)\n",
            "/Aren't you?  Aren't you indicating that I should not tell other people what\n",
            "to do?  Aren't you telling me it is wrong for me to do that? \n",
            "\n",
            "It is not a moral standard that I am presenting you with, Hudson.  It is\n",
            "a key to getting along in life with other people.  It is also a point of\n",
            "respect:  I trust other people to be intelligent enough to make their\n",
            "own choices, and I expect the same to be returned.  You, on the other\n",
            "hand, do not trust them, and want to make the choice for them--whether\n",
            "they like it or not.\n",
            "\n",
            "It is also a way to avoid an inconsistency:  if you believe that you have \n",
            "the right to set moral standards for others and interfere in their lives, \n",
            "then you must, by logic, admit that other people have the same right of \n",
            "interference in your life.  \n",
            "(Yes, I know; you will say that your religion is correct and tells you that\n",
            "only agents acting in behalf of your religion have the right of interference.\n",
            "However, other people will say that you have misinterpreted the Word of\n",
            "God and that *they* are the actual true believers, and that you are\n",
            "acting on your own authority.  And so it goes).\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "(hudson)\n",
            "/Who gave\n",
            "/you the authority to set such a moral standard for me to tell me that I \n",
            "/cannot set a moral standard for others?\n",
            "\n",
            "\n",
            "You can set all the standards that you want, actually.  But don't be surprised\n",
            "if people don't follow you like rats after the Pied Piper.  \n",
            "\n",
            "At the most basic form, I am not going to LET you tell me what to do;\n",
            "and if necessary, I will beat you to a bloody pulp before I let you actually\n",
            "interfere in my life.\n"
          ]
        }
      ],
      "source": [
        "# Veamos similaridad de documentos. Tomemos algún documento\n",
        "idx = 8754\n",
        "print(newsgroups_train.data[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ssa9bqJ-hA_v"
      },
      "outputs": [],
      "source": [
        "# midamos la similaridad coseno con todos los documentos de train\n",
        "cossim = cosine_similarity(X_train[idx], X_train)[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cossim"
      ],
      "metadata": {
        "id": "qQWdijV_-ClO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbe20c06-5fd6-4460-ee5d-5c71e769307f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.11252759, 0.09561582, 0.17267024, ..., 0.09162675, 0.1121114 ,\n",
              "       0.03334953])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_mDA7p3AzcQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe70fb34-73b1-4eef-d264-f593d86c69eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 0.49040531, 0.48118373, ..., 0.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# podemos ver los valores de similaridad ordenados de mayor a menos\n",
        "np.sort(cossim)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OIhDA1jAryX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d305691-b7e4-4dc1-8c36-e81e8a907e11"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8754,  6552, 10613, ...,  6988,  6980,  9520])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# y a qué documentos corresponden\n",
        "np.argsort(cossim)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hP7qLS4ZBLps"
      },
      "outputs": [],
      "source": [
        "# los 5 documentos más similares:\n",
        "mostsim = np.argsort(cossim)[::-1][1:6]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mostsim"
      ],
      "metadata": {
        "id": "Y1SFEyIIKBOI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26861582-75b0-4164-b5e6-2a4a21260b30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6552, 10613,  3616,  8726,  3902])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdJLHPJACvaj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bd95bf04-c951-4633-a32e-42d654b67d30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'talk.religion.misc'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "# el documento original pertenece a la clase:\n",
        "newsgroups_train.target_names[y_train[idx]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWy_73epCbFG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed32ed1e-1cbe-4ba8-ac26-5cd68ecfbda3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "talk.religion.misc\n",
            "talk.religion.misc\n",
            "talk.religion.misc\n",
            "talk.politics.mideast\n",
            "talk.religion.misc\n"
          ]
        }
      ],
      "source": [
        "# y los 5 más similares son de las clases:\n",
        "for i in mostsim:\n",
        "  print(newsgroups_train.target_names[y_train[i]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRoNnKwhBqzq"
      },
      "source": [
        "### Modelo de clasificación Naïve Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPM0thDaLk0R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "51b527f2-77fd-475f-e2c0-661f21ab4e6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "# es muy fácil instanciar un modelo de clasificación Naïve Bayes y entrenarlo con sklearn\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrQjzM48Mu4T"
      },
      "outputs": [],
      "source": [
        "# con nuestro vectorizador ya fiteado en train, vectorizamos los textos\n",
        "# del conjunto de test\n",
        "X_test = tfidfvect.transform(newsgroups_test.data)\n",
        "y_test = newsgroups_test.target\n",
        "y_pred =  clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkGJhetEPdA4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97c011cc-efa3-491f-ce30-929872f7b3e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5854345727938506"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "# el F1-score es una metrica adecuada para reportar desempeño de modelos de claificación\n",
        "# es robusta al desbalance de clases. El promediado 'macro' es el promedio de los\n",
        "# F1-score de cada clase. El promedio 'micro' es equivalente a la accuracy que no\n",
        "# es una buena métrica cuando los datasets son desbalanceados\n",
        "f1_score(y_test, y_pred, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McArD4rSDR2K"
      },
      "source": [
        "### Consigna del desafío\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJgf6GQIIEH1"
      },
      "source": [
        "**1**. Vectorizar documentos. Tomar 5 documentos al azar y medir similaridad con el resto de los documentos.\n",
        "Estudiar los 5 documentos más similares de cada uno analizar si tiene sentido\n",
        "la similaridad según el contenido del texto y la etiqueta de clasificación.\n",
        "\n",
        "**No puedes usar la misma solución ya presentada por alguien en el foro antes que Ud. Es decir, sus 5 documentos al azar deben ser diferentes a los ya presentados, o las palabras que elija para el ejercicio 3 deben ser diferentes a las ya presentadas.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importo las librerias"
      ],
      "metadata": {
        "id": "Mqvwa003LN_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importo numpy para operaciones numéricas y manejo eficiente de arrays\n",
        "import numpy as np\n",
        "\n",
        "# importo CountVectorizer para transformar texto en matriz de conteo\n",
        "# e importo TfidfVectorizer para transformar texto en matriz TF-IDF\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# importo cosine_similarity para calcular la similitud coseno entre vectores\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# importo MultinomialNB y ComplementNB, clasificadores Naive Bayes adecuados para texto/conteos\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "\n",
        "# importo f1_score para evaluar el rendimiento del modelo combinando precisión y recall en una métrica\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# importo fetch_20newsgroups para descargar/cargar el dataset de 20 categorías de noticias\n",
        "from sklearn.datasets import fetch_20newsgroups"
      ],
      "metadata": {
        "id": "dqFwQL_iW81Y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carga de datos\n"
      ],
      "metadata": {
        "id": "cG0-n1ySLkRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# descargo el conjunto de entrenamiento del dataset \"20 newsgroups\" indicando subset='train'\n",
        "# elimino headers, footers y quotes para quedarme solo con el cuerpo del mensaje\n",
        "# obtengo un objeto tipo Bunch que contiene .data (lista de textos), .target (etiquetas numéricas) y .target_names (nombres de las categorías)\n",
        "train_group = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "# descargo el conjunto de prueba (subset='test') con la misma limpieza de headers, footers y quotes\n",
        "# el objeto resultante también incluye .data, .target y .target_names para evaluación del modelo\n",
        "test_group = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
      ],
      "metadata": {
        "id": "_1vcvi_cYWoo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vectorización\n"
      ],
      "metadata": {
        "id": "_c-uEN7bLtQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creo un TfidfVectorizer para transformar los documentos en vectores TF-IDF (pondera frecuencia por importancia)\n",
        "# configuro stop_words='english' para eliminar palabras vacías comunes en inglés y reducir ruido en la representación\n",
        "Tfidf_vectorizer = TfidfVectorizer(stop_words='english')"
      ],
      "metadata": {
        "id": "cZJqTEimLwHC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ajusto el Tfidf_vectorizer con los textos de entrenamiento y transformo esos textos en una matriz TF-IDF\n",
        "# obtengo una matriz dispersa de forma (n_muestras, n_características) donde cada fila representa un documento\n",
        "X_train = Tfidf_vectorizer.fit_transform(train_group.data)\n",
        "\n",
        "# transformo los textos de test usando el vectorizador ya ajustado (no vuelvo a ajustar para conservar el mismo vocabulario)\n",
        "# la salida es otra matriz TF-IDF dispersa compatible con X_train para evaluación\n",
        "X_test = Tfidf_vectorizer.transform(test_group.data)\n",
        "\n",
        "# extraigo las etiquetas numéricas (clases) del conjunto de entrenamiento\n",
        "y_train = train_group.target\n",
        "\n",
        "# extraigo las etiquetas numéricas (clases) del conjunto de prueba para comparar predicciones posteriormente\n",
        "y_test = test_group.target"
      ],
      "metadata": {
        "id": "4rhUxtuKMCsD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# muestro el tipo de objeto de X_train\n",
        "print(type(X_train))\n",
        "\n",
        "# muestro la forma de la matriz: (n_muestras, n_características)\n",
        "print(f'shape: {X_train.shape}')\n",
        "\n",
        "# imprimo la cantidad de documentos (número de filas de la matriz)\n",
        "print(f'cantidad de documentos: {X_train.shape[0]}')\n",
        "\n",
        "# imprimo el tamaño del vocabulario / dimensionalidad de los vectores (número de columnas)\n",
        "print(f'tamaño del vocabulario (dimensionalidad de los vectores): {X_train.shape[1]}')"
      ],
      "metadata": {
        "id": "2923jRVvMea6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61bccb97-2d92-4c4c-d2d9-f910870e85cc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'>\n",
            "shape: (11314, 101322)\n",
            "cantidad de documentos: 11314\n",
            "tamaño del vocabulario (dimensionalidad de los vectores): 101322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# muestro el tipo de objeto de X_test\n",
        "print(type(X_test))\n",
        "\n",
        "# muestro la forma de la matriz de test: (n_muestras, n_características)\n",
        "print(f'shape: {X_test.shape}')\n",
        "\n",
        "# imprimo la cantidad de documentos en el conjunto de test (número de filas)\n",
        "print(f'cantidad de documentos: {X_test.shape[0]}')\n",
        "\n",
        "# imprimo el tamaño del vocabulario / dimensionalidad de los vectores en test (número de columnas)\n",
        "print(f'tamaño del vocabulario (dimensionalidad de los vectores): {X_test.shape[1]}')"
      ],
      "metadata": {
        "id": "qAhFvJJZMh3y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76065f20-5fbe-4c0a-8fe2-17d49e2310ac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'>\n",
            "shape: (7532, 101322)\n",
            "cantidad de documentos: 7532\n",
            "tamaño del vocabulario (dimensionalidad de los vectores): 101322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Similaridad de documentos\n"
      ],
      "metadata": {
        "id": "ly5bSHMsM5q6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fijo la semilla de numpy en 42 para que las selecciones aleatorias sean reproducibles\n",
        "np.random.seed(42)\n",
        "\n",
        "# selecciono 5 índices únicos de documentos del conjunto de entrenamiento\n",
        "# X_train.shape[0] es el número total de documentos; size=5 pide 5 índices; replace=False evita índices repetidos\n",
        "random_docs = np.random.choice(X_train.shape[0], size=5, replace=False)\n",
        "\n",
        "# imprimo los índices de los documentos seleccionados\n",
        "print(f\"Documentos seleccionados: {random_docs}\")"
      ],
      "metadata": {
        "id": "PDwuiBPHM60K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b3c0d63-7202-4572-c2ab-0ad945b5d4a7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documentos seleccionados: [7492 3546 5582 4793 3813]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# itero sobre los índices de los documentos seleccionados aleatoriamente\n",
        "for idx in random_docs:\n",
        "  # imprimo un separador visual para distinguir bloques\n",
        "  print(\"=\" * 100)\n",
        "  # indico el índice del documento que se está mostrando\n",
        "  print(f\"Documento original (índice {idx}):\")\n",
        "  # recupero e imprimo el nombre de la clase usando el array de targets y target_names\n",
        "  print(\"Clase:\", train_group.target_names[y_train[idx]])\n",
        "  # muestro una vista previa de los primeros 500 caracteres del documento para inspección rápida\n",
        "  print(f'Preview: {train_group.data[idx][:500]} ...')\n",
        "  # imprimo otro separador para separar la previsualización de la sección de similares\n",
        "  print(\"=\" * 100)\n",
        "\n",
        "  # calculo la similitud coseno entre el documento actual (fila idx) y todos los documentos de entrenamiento\n",
        "  # el resultado es una matriz 1xN; con [0] obtengo el vector 1D de similaridades\n",
        "  cossim = cosine_similarity(X_train[idx], X_train)[0]\n",
        "\n",
        "  # ordeno los índices por similaridad ascendente con np.argsort, invierto el orden para tener descendente\n",
        "  # [1:6] excluye el propio documento (posición 0) y toma los 5 documentos más similares\n",
        "  mostsim = np.argsort(cossim)[::-1][1:6] # Obtener los 5 documentos más similares al actual\n",
        "\n",
        "  # indico que voy a listar los documentos más similares\n",
        "  print(\"5 documentos más similares:\")\n",
        "  # itero sobre los índices de los documentos más similares y su posición en la lista\n",
        "  for i, sim_idx in enumerate(mostsim):\n",
        "    # muestro un salto de línea y el número de similar (1..5), el índice del documento y la similaridad formateada\n",
        "    print(f\"\\nSimilar {i+1} (índice {sim_idx}, similaridad {cossim[sim_idx]:.4f}):\")\n",
        "    # recupero e imprimo la clase del documento similar\n",
        "    print(\"Clase:\", train_group.target_names[y_train[sim_idx]])\n",
        "    # muestro una previsualización del documento similar (primeros 500 caracteres)\n",
        "    print(f'Preview: {train_group.data[sim_idx][:500]} ...')"
      ],
      "metadata": {
        "id": "eHYI1XybNoMC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2d6dd3c-cc19-4649-a15d-84ed873d618a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "Documento original (índice 7492):\n",
            "Clase: comp.sys.mac.hardware\n",
            "Preview: Could someone please post any info on these systems.\n",
            "\n",
            "Thanks.\n",
            "BoB\n",
            "-- \n",
            "---------------------------------------------------------------------- \n",
            "Robert Novitskey | \"Pursuing women is similar to banging one's head\n",
            "rrn@po.cwru.edu  |  against a wall...with less opportunity for reward\"  ...\n",
            "====================================================================================================\n",
            "5 documentos más similares:\n",
            "\n",
            "Similar 1 (índice 10935, similaridad 0.7025):\n",
            "Clase: comp.sys.mac.hardware\n",
            "Preview: Hey everybody:\n",
            "\n",
            "   I want to buy a mac and I want to get a good price...who doesn't?  So,\n",
            "could anyone out there who has found a really good deal on a Centris 650\n",
            "send me the price.  I don't want to know where, unless it is mail order or\n",
            "areound cleveland, Ohio.  Also, should I buy now or wait for the Power PC.\n",
            "\n",
            "Thanks.\n",
            "BoB\n",
            "reply via post or e-mail at rrn@po.cwru.edu\n",
            "-- \n",
            "---------------------------------------------------------------------- \n",
            "Robert Novitskey | \"Pursuing women is similar to bangi ...\n",
            "\n",
            "Similar 2 (índice 7258, similaridad 0.3700):\n",
            "Clase: comp.sys.ibm.pc.hardware\n",
            "Preview: Hay all:\n",
            "\n",
            "    Has anyone out there heard of any performance stats on the fabled p24t.\n",
            " I was wondering what it's performance compared to the 486/66 and/or\n",
            "pentium would be.  Any info would be helpful.\n",
            "\n",
            "Later\n",
            "BoB\n",
            "-- \n",
            "Robert Novitskey | rrn@po.cwru.edu | (216)754-2134 | CWRU Cleve. Ohio\n",
            "----------------------------------------------------------------------\n",
            "COMPUTER ENGINEER AND C PROGRAMMER |  NOW SEEKING SUMMER JOBS ...\n",
            "\n",
            "Similar 3 (índice 4971, similaridad 0.1519):\n",
            "Clase: comp.sys.mac.hardware\n",
            "Preview: Could someone please send instructions for installing simms and vram to \n",
            "jmk13@po.cwru.edu?  He's just gotten his 700 and wants to drop in some \n",
            "extra simms and vram that he has for it. ...\n",
            "\n",
            "Similar 4 (índice 4303, similaridad 0.1473):\n",
            "Clase: misc.forsale\n",
            "Preview: For sale:\n",
            "\n",
            "Roland D-50: $700 or best offer.\n",
            "Excellent condition.\n",
            "Includes over 1000 patches on disk (In cakewalk sysex format)\n",
            "\n",
            "Buyer must pay COD shipping.\n",
            "\n",
            "Please e-mail responses to:\n",
            "gms2@po.cwru.edu\n",
            "\n",
            "Thanks.\n",
            "\n",
            "George\n",
            " ...\n",
            "\n",
            "Similar 5 (índice 3580, similaridad 0.1359):\n",
            "Clase: alt.atheism\n",
            "Preview: who: kmr4@po.CWRU.edu (Keith M. Ryan)\n",
            "what: <kmr4.1426.733987668@po.cwru.edu>\n",
            "with: rush@leland.Stanford.EDU \n",
            "what: <1993Apr5.050524.9361@leland.Stanford.EDU>\n",
            " \n",
            " \n",
            "KR> \"Sadly yes. Don't loose any sleep over Old 'Zlumber. Just\n",
            "KR> have some fun with him, but he is basically harmless. \n",
            "KR> At least, if you don't work in NY city.\"\n",
            " \n",
            "I don't find it hard to believe that \"Ole 'Zlumber\" really believes\n",
            "the hate and ignorant prattle he writes. The frightening thought is,\n",
            "there are people even worse than ...\n",
            "====================================================================================================\n",
            "Documento original (índice 3546):\n",
            "Clase: comp.os.ms-windows.misc\n",
            "Preview: \n",
            "\n",
            "     Don't bother if you have CPBackup or Fastback.  They all offer options \n",
            "not available in the stripped-down MS version (FROM CPS!).  Examples - no \n",
            "proprietary format (to save space), probably no direct DMA access, and no \n",
            "tape drive! ...\n",
            "====================================================================================================\n",
            "5 documentos más similares:\n",
            "\n",
            "Similar 1 (índice 5665, similaridad 0.1996):\n",
            "Clase: comp.sys.ibm.pc.hardware\n",
            "Preview: \n",
            "By initiating a DMA xfer.  :)\n",
            "\n",
            "Seriously, busmastering adapter have their own DMA ability, they don't use\n",
            "the motherboards on-board DMA(which is *MUCH* slower).\n",
            "\n",
            "ISA has no bus arbitration, so if two busmastering cards in 1 ISA system\n",
            "try to do DMA xfers on the same DMA channel the system will lock or \n",
            "crash.(I forget)\n",
            "\n",
            "Their are 8 DMA channels in an ISA system. 0-7. 0-3 are 8-bit & 4-7 are\n",
            "16-bit.\n",
            "\n",
            "The system uses DMA 0, a SoundBlaster uses DMA 1.\n",
            "\n",
            "I could buy a busmastering XGA-2 video card & ...\n",
            "\n",
            "Similar 2 (índice 2011, similaridad 0.1899):\n",
            "Clase: comp.sys.ibm.pc.hardware\n",
            "Preview: \n",
            "\n",
            "IDE also uses DMA techniques.  I believe floppy controller also uses DMA,\n",
            "and most A/D boards also use DMA.  DMA is no big deal, and has nothing to\n",
            "do directly with SCSI.\n",
            "\n",
            "\n",
            "You can thank your software for that.  If DOS had a few more brains, it\n",
            "could format floppies etc. while you were doing something else.  The\n",
            "hardware will support it, but DOS (at least) won't.  Again, this has   \n",
            "nothing to do with SCSI.\n",
            "\n",
            "\n",
            "And if you stick with DOS you'll wonder why you can't multitask. ...\n",
            "\n",
            "Similar 3 (índice 8765, similaridad 0.1702):\n",
            "Clase: comp.sys.ibm.pc.hardware\n",
            "Preview: The floppy is served by DMA on the motherboard,\n",
            "and original DMA-controller can't reach more than the first\n",
            "16MB (The address-space of the ISA-bus)\n",
            "joerg\n",
            " ...\n",
            "\n",
            "Similar 4 (índice 8643, similaridad 0.1670):\n",
            "Clase: comp.sys.ibm.pc.hardware\n",
            "Preview: \n",
            "There would be no problems as long as the OS didn't set up a DMA transfer\n",
            "to an area above the 16 mb area (the DMA controller probably can't be\n",
            "programmed that way anyways, so there probably isin't a problem with this) ...\n",
            "\n",
            "Similar 5 (índice 1546, similaridad 0.1416):\n",
            "Clase: comp.sys.ibm.pc.hardware\n",
            "Preview: \n",
            "\n",
            "     Here's a document that I wrote some time back.  It's slightly\n",
            "out-of-date, now that DOS 6 has been released, but much of it is still\n",
            "useful.\n",
            "\n",
            "     -- Darryl Okahata\n",
            "\tInternet: darrylo@sr.hp.com\n",
            "\n",
            "DISCLAIMER: this message is the author's personal opinion and does not\n",
            "constitute the support, opinion or policy of Hewlett-Packard or of the\n",
            "little green men that have been following him all day.\n",
            "\n",
            "===============================================================================\n",
            "$Id: adaptec.txt 1.8 ...\n",
            "====================================================================================================\n",
            "Documento original (índice 5582):\n",
            "Clase: misc.forsale\n",
            "Preview: 5.25\" Internal Low density disk drive.\n",
            "\n",
            "Monochrome monitor\n",
            "\n",
            "8088 motherboard, built in parallel and serial ports, built in mono and\n",
            "color output, 7Mhz.\n",
            "\n",
            "Libertarian, atheist, semi-anarchal Techno-Rat. ...\n",
            "====================================================================================================\n",
            "5 documentos más similares:\n",
            "\n",
            "Similar 1 (índice 5510, similaridad 0.4901):\n",
            "Clase: misc.forsale\n",
            "Preview: I am looking for a 286 motherboard, preferable 12 or 16, 640k or 1 meg RAM. \n",
            "I am also looking for a VGA card.\n",
            "\n",
            "Am willing to trade 1200 external, 5.25\" LD Drive, 8088 motherboard,\n",
            "monochrome monitor, Game Boy, in some combination for the above.\n",
            "\n",
            "Libertarian, atheist, semi-anarchal Techno-Rat. ...\n",
            "\n",
            "Similar 2 (índice 4922, similaridad 0.3050):\n",
            "Clase: misc.forsale\n",
            "Preview: For sale:\n",
            "\n",
            "Nintendo Game Boy, Tetris, Castlevania Adventure, All-Star Challenge,\n",
            "Nemesis, Play-Action football, link cable.\n",
            "\n",
            "Make me an offer.\n",
            "\n",
            "Libertarian, atheist, semi-anarchal Techno-Rat. ...\n",
            "\n",
            "Similar 3 (índice 4347, similaridad 0.2889):\n",
            "Clase: comp.graphics\n",
            "Preview: \n",
            "\n",
            "It's really not that hard to do.  There are books out there which explain\n",
            "everything, and the basic 3D functions, translation, rotation, shading, and\n",
            "hidden line removal are pretty easy.  I wrote a program in a few weeks witht\n",
            "he help of a book, and would be happy to give you my source.\n",
            "\tAlso, Quickdraw has a lot of 3D functions built in, and Think pascal\n",
            "can access them, and I would expect that THINK C could as well.  If you can\n",
            "find out how to use the Quickdraw graphics library, it would be  ...\n",
            "\n",
            "Similar 4 (índice 8057, similaridad 0.2036):\n",
            "Clase: misc.forsale\n",
            "Preview: Hello, I have a motherboard and a case for sale as a package.\n",
            "Both of them came from a CompuAdd computer I bought last August and am \n",
            "  presently upgrading.\n",
            "Here are the specs--\n",
            "\n",
            "Motherboard\n",
            "-----------\n",
            "Cyrix 486SL 25 MHz microprocessor\n",
            "Chips and Technology chipset (SCATsx V2.3.6 SLSLC)\n",
            "8 SIMM banks for a maximum of 32 Megs of RAM\n",
            "BUILT-IN Floppy and Hard Drive Controllers\n",
            "BUILT-IN ports--1 Parallel, 2 Serial (9 and 25 pin)\n",
            "BUILT-IN Paradise SVGA controller with 1 meg of RAM (Windows drivers inc ...\n",
            "\n",
            "Similar 5 (índice 4028, similaridad 0.1708):\n",
            "Clase: comp.graphics\n",
            "Preview: Hello, and thank you for reading this request.  I have a Mpeg viewer for x-windows and it did not run because I was running it on a monochrome monitor.  I need the mono-driver for mpeg_play.    ...\n",
            "====================================================================================================\n",
            "Documento original (índice 4793):\n",
            "Clase: talk.politics.guns\n",
            "Preview: Hi,\n",
            "\n",
            "In Canada, any gun that enters a National Park must be sealed (I think it's a\n",
            "small metal tag that's placed over the trigger).  The net result of this is\n",
            "that you _can't_ use a gun to protect yourself from bears (or psychos) in the\n",
            "National Parks.  Instead, one has to be sensitive to the dangers and annoyances\n",
            "of hiking in bear country, and take the appropriate precautions.\n",
            "\n",
            "I think this policy makes the users of the National Parks feel a little closer\n",
            "to Nature, that they are a part of Nat ...\n",
            "====================================================================================================\n",
            "5 documentos más similares:\n",
            "\n",
            "Similar 1 (índice 10468, similaridad 0.1767):\n",
            "Clase: comp.sys.mac.hardware\n",
            "Preview: \n",
            "   I believe that E-Machines might produce something of this nature.\n",
            "  ...\n",
            "\n",
            "Similar 2 (índice 382, similaridad 0.1682):\n",
            "Clase: talk.politics.guns\n",
            "Preview: \n",
            "Hello,\n",
            "\n",
            "\tI understand this philosophy.  The bears are a national\n",
            "treasure, the area is their sanctuary and people who enter it\n",
            "do so at their own risk.  It is better that that rare human be\n",
            "killed by a bear than that bears be provoked or shot by unbear-savvy\n",
            "visitors.  The bears aren't having a population explosion, humans\n",
            "are so it is better that a human be killed than endanger the bears.\n",
            "I don't agree with this philosopy, but I understand it.\n",
            "\n",
            "\tThe psychos are a bit different.  They are not a ...\n",
            "\n",
            "Similar 3 (índice 495, similaridad 0.1274):\n",
            "Clase: alt.atheism\n",
            "Preview: : \n",
            ": >> Please enlighten me.  How is omnipotence contradictory?\n",
            ": \n",
            ": >By definition, all that can occur in the universe is governed by the rules\n",
            ": >of nature. Thus god cannot break them. Anything that god does must be allowed\n",
            ": >in the rules somewhere. Therefore, omnipotence CANNOT exist! It contradicts\n",
            ": >the rules of nature.\n",
            ": \n",
            ": Obviously, an omnipotent god can change the rules.\n",
            "\n",
            "When you say, \"By definition\", what exactly is being defined;\n",
            "certainly not omnipotence. You seem to be saying tha ...\n",
            "\n",
            "Similar 4 (índice 10786, similaridad 0.1263):\n",
            "Clase: talk.politics.guns\n",
            "Preview: \n",
            "You're getting warmer.  The 'little thing in the trigger' has to be\n",
            "depressed before the trigger can move.  What this means is the damned\n",
            "thing won't go off until the trigger is pulled.  This makes it just\n",
            "about (there HAVE been some problems, but we're assuming the gun is\n",
            "functioning correctly..) as safe as a revolver.  The gun when working\n",
            "correctly is totally drop safe.\n",
            "\n",
            "Now, in police work this is a consideration.  There is not a single\n",
            "documented case I'm aware of where a police officer wa ...\n",
            "\n",
            "Similar 5 (índice 11036, similaridad 0.1174):\n",
            "Clase: talk.politics.guns\n",
            "Preview: \n",
            "\tAt the risk of starting the 'my gun is better than yours' flame\n",
            "war, I must disagree.\n",
            "\t\n",
            "\tThere is no secret in handling a Glock.  In fact, it is often\n",
            "chosen (besides its other merits) because it shoots like a revolver does\n",
            "basically.  It can limit the training time (read budget $$$) due to the\n",
            "fact there are no 'external' safties other than the trigger, hence less\n",
            "training time required. \n",
            "\n",
            "\tSmith & Wesson (among other types) are chosen due to the fact taht\n",
            "they do have the external safties (h ...\n",
            "====================================================================================================\n",
            "Documento original (índice 3813):\n",
            "Clase: rec.sport.hockey\n",
            "Preview: \n",
            "Doesn't it also have the Statue of Liberty on it or is that Richter's Mask?\n",
            "\n",
            "The back actually has a Bee followed by a Z to represent the Beezer. It \n",
            "also has something that looks like the three interconnecting circles from\n",
            "the Led Zepplin 4 album cover. Is that what it is supposed to be? and if\n",
            "it is does anybody know why he would put it there? Ali?\n",
            "\n",
            "\n",
            "John\n",
            "\"The official Language of Golf is Profanity\"\n",
            "\n",
            "\n",
            " ...\n",
            "====================================================================================================\n",
            "5 documentos más similares:\n",
            "\n",
            "Similar 1 (índice 7525, similaridad 0.1405):\n",
            "Clase: rec.sport.hockey\n",
            "Preview: My vote goes to John Vanbiesbrouck.  His mask has a skyline of New York\n",
            "City, and on the sides there are a bunch of bees (Beezer).  It looks\n",
            "really sharp.\n",
            "\n",
            "--\n",
            "    Keith Keller\t\t\t\tLET'S GO RANGERS!!!!!\n",
            "\t\t\t\t\t\tLET'S GO QUAKERS!!!!!\n",
            "\tkkeller@mail.sas.upenn.edu\t\tIVY LEAGUE CHAMPS!!!! ...\n",
            "\n",
            "Similar 2 (índice 10480, similaridad 0.1109):\n",
            "Clase: sci.med\n",
            "Preview: \n",
            "\n",
            "does anyone know?\n",
            "\n",
            "--  ...\n",
            "\n",
            "Similar 3 (índice 2399, similaridad 0.0992):\n",
            "Clase: comp.sys.ibm.pc.hardware\n",
            "Preview: : \n",
            ": \n",
            ": Shadow mask is when you put your face into\n",
            ": main memory.\n",
            ":  ...\n",
            "\n",
            "Similar 4 (índice 860, similaridad 0.0976):\n",
            "Clase: talk.politics.mideast\n",
            "Preview: \n",
            "\n",
            "\n",
            "This is an interesting question to ponder.  Did Brad/Ali's sickness\n",
            "make Ayatollah-style Islam attractive to him or did this new religion \n",
            "that Brad/Ali has formally adopted give him this sickness?\n",
            " ...\n",
            "\n",
            "Similar 5 (índice 6125, similaridad 0.0935):\n",
            "Clase: rec.sport.hockey\n",
            "Preview: \n",
            "It would seem logical that the mask is Potvins. His nickname is \"The Cat\", \n",
            "which would go a long ways towards explaining the panther. \n",
            "\n",
            "Of course, it could be an old story and the mask is Fuhrs, too..... ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Primer Documento:\n"
      ],
      "metadata": {
        "id": "fUSX3jzLVqnR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para el documento 7492 (comp.sys.mac.hardware, consulta sobre sistemas Mac), la similitud coseno identifica correctamente documentos similares en la misma categoría, como otro post del mismo usuario sobre compras de Centris 650 (similaridad 0.7025), lo que tiene sentido por el contexto de hardware Apple y firmas idénticas. Sin embargo, algunos similares divergen hacia hardware IBM debido a brevedad y palabras comunes como \"BoB\", y la ultima pasa directamente a una clase distinta sin similitud aparente, destacando limitaciones en textos cortos, aunque TF-IDF captura bien temas relacionados."
      ],
      "metadata": {
        "id": "rylgI9kIVtKz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Segundo Documento:\n"
      ],
      "metadata": {
        "id": "71ihwH0FVtr7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el documento 3546 (comp.os.ms-windows.misc, sobre backups en Windows), las similitudes se alinean lógicamente con discusiones técnicas de hardware PC, como DMA y controladores (e.g., similaridad 0.1996 con un post sobre busmastering), reflejando coherencia temática en categorías de sistemas IBM. Esto valida la efectividad de TF-IDF para vincular contenidos técnicos, aunque las similitudes son moderadas por la especificidad del tema."
      ],
      "metadata": {
        "id": "S0JnWvpUVuur"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tercer documento:\n"
      ],
      "metadata": {
        "id": "OcmBKXWqVxE7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El documento 5582 (misc.forsale, venta de componentes como drives y motherboards), muestra alta similitud con otras ofertas de hardware (e.g., 0.4901 con un post buscando motherboards 286), coherente con la etiqueta de ventas. Incluye cruces con gráficos por menciones técnicas, confirmando que la vectorización captura patrones de comercio y specs."
      ],
      "metadata": {
        "id": "LFixt-fgVyUT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cuarto Documento:\n"
      ],
      "metadata": {
        "id": "efUIOkeFVy5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para el 4793 (talk.politics.guns, política de armas en parques nacionales), las similitudes son más débiles (e.g., 0.1767 con un post breve sobre hardware), luego cruza nuevamente otras categorias de politicas, tocando temas como armas, naturaleza u omnipotencia en ateísmo. Esto indica que TF-IDF detecta temas colaterales como riesgos, aunque la ambigüedad reduce precisión, sugiriendo necesidad de embeddings más avanzados para contextos políticos."
      ],
      "metadata": {
        "id": "SWPsg2K6V1DD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quinto Documento:\n"
      ],
      "metadata": {
        "id": "3qwa7MKKV1XT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El documento 3813 (rec.sport.hockey, temas generales), se vincula bien con otros posts de hockey, como el primer similar 0.1405 que trata temas muy similares, o almenos la forma textual es similar, confirmando relevancia temática en deportes. Similitudes menores con temas variados muestran límites en textos cortos, pero generales, TF-IDF valida similitudes basadas en contenido y etiquetas, enfatizando su utilidad para clustering temático."
      ],
      "metadata": {
        "id": "FeVTFI0rWtY8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**2**. Transponer la matriz documento-término. De esa manera se obtiene una matriz\n",
        "término-documento que puede ser interpretada como una colección de vectorización de palabras.\n",
        "Estudiar ahora similaridad entre palabras tomando 5 palabras y estudiando sus 5 más similares. **La elección de palabras no debe ser al azar para evitar la aparición de términos poco interpretables, elegirlas \"manualmente\"**."
      ],
      "metadata": {
        "id": "JS1u_5kle7U8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transpongo la matriz TF-IDF para cambiar la orientación: ahora filas = términos, columnas = documentos\n",
        "# la nueva forma será (n_características, n_muestras) — es decir (tamaño del vocabulario, cantidad de documentos)\n",
        "X_terms = X_train.T"
      ],
      "metadata": {
        "id": "DmfG6DCYW9Kt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# elijo las 5 palabras manualmente\n",
        "palabras = ['computer', 'god', 'car', 'space', 'politics']"
      ],
      "metadata": {
        "id": "tJEJ_l3Wc04F"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dado 'palabras' (lista de términos), obtengo para cada término su índice en el vocabulario del vectorizador TF-IDF\n",
        "# uso vocabulary_.get(p, None) para devolver None cuando el término no está presente en el vocabulario (evito KeyError)\n",
        "# el resultado es una lista de índices (o None) con la misma longitud que 'palabras'\n",
        "indice_de_palabras = [Tfidf_vectorizer.vocabulary_.get(p, None) for p in palabras]"
      ],
      "metadata": {
        "id": "0BV4Zyo2hF1d"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obtengo la lista completa de nombres de características (palabras del vocabulario) generada por el vectorizador TF-IDF\n",
        "# get_feature_names_out() devuelve un array con todas las palabras asociadas a las columnas de la matriz TF-IDF\n",
        "feature_names = Tfidf_vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "25GLWqfOd9QF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# itero sobre pares (índice_de_palabra, palabra) alineados con zip para procesar cada término seleccionado\n",
        "for idx, palabra in zip(indice_de_palabras, palabras):\n",
        "  # verifico que el término exista en el vocabulario del vectorizador (evito errores si no está)\n",
        "  if palabra in Tfidf_vectorizer.vocabulary_:\n",
        "    # separador visual para facilitar lectura en consola\n",
        "    print(\"=\"*100)\n",
        "    # muestro el término original y su índice en el vocabulario\n",
        "    print(f\"\\nPalabra original: {palabra} (índice {idx})\")\n",
        "    # calculo la similitud coseno entre el vector del término actual (fila idx de X_terms)\n",
        "    # y todos los vectores de términos; uso reshape(1, -1) para convertirlo en una fila 2D compatible\n",
        "    # el resultado 'cossim_words' es un vector con la similitud del término con cada término del vocabulario\n",
        "    cossim_words = cosine_similarity(X_terms[idx].reshape(1, -1), X_terms)[0]\n",
        "\n",
        "    # ordeno los índices por similaridad descendente y omito el primero (es el mismo término)\n",
        "    # [1:6] devuelve los 5 términos más similares distintos del término actual\n",
        "    mostsim_words = np.argsort(cossim_words)[::-1][1:6]\n",
        "\n",
        "    # aviso que voy a listar las 5 palabras más similares\n",
        "    print(\"5 palabras más similares:\")\n",
        "    # itero simultáneamente sobre los índices más similares y sus valores de similaridad\n",
        "    for i, similaridad in zip(mostsim_words, cossim_words[mostsim_words]):\n",
        "        # muestro el índice, la palabra correspondiente (mediante feature_names) y la similaridad formateada\n",
        "        print(f\"indice {i}, Palabra: {feature_names[i]}, similaridad: {similaridad:.4f}\")\n",
        "  # si el término no está en el vocabulario, imprimo un aviso claro\n",
        "  else: print(f\"\\nPalabra '{palabra}' no esta en vocabulario.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wc4WOQIohZHV",
        "outputId": "03d15a1c-f950-434d-9ce2-1db54aa9f86d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "\n",
            "Palabra original: computer (índice 28881)\n",
            "5 palabras más similares:\n",
            "indice 32323, Palabra: decwriter, similaridad: 0.1579\n",
            "indice 45612, Palabra: harkens, similaridad: 0.1531\n",
            "indice 32658, Palabra: deluged, similaridad: 0.1531\n",
            "indice 82134, Palabra: shopper, similaridad: 0.1421\n",
            "indice 32606, Palabra: delicate, similaridad: 0.1366\n",
            "====================================================================================================\n",
            "\n",
            "Palabra original: god (índice 43733)\n",
            "5 palabras más similares:\n",
            "indice 52019, Palabra: jesus, similaridad: 0.2806\n",
            "indice 22649, Palabra: bible, similaridad: 0.2764\n",
            "indice 27138, Palabra: christ, similaridad: 0.2668\n",
            "indice 39317, Palabra: faith, similaridad: 0.2593\n",
            "indice 38539, Palabra: existence, similaridad: 0.2589\n",
            "====================================================================================================\n",
            "\n",
            "Palabra original: car (índice 25717)\n",
            "5 palabras más similares:\n",
            "indice 25863, Palabra: cars, similaridad: 0.1898\n",
            "indice 30471, Palabra: criterium, similaridad: 0.1732\n",
            "indice 32086, Palabra: dealer, similaridad: 0.1732\n",
            "indice 27504, Palabra: civic, similaridad: 0.1713\n",
            "indice 69023, Palabra: owner, similaridad: 0.1644\n",
            "====================================================================================================\n",
            "\n",
            "Palabra original: space (índice 83871)\n",
            "5 palabras más similares:\n",
            "indice 64845, Palabra: nasa, similaridad: 0.3279\n",
            "indice 82292, Palabra: shuttle, similaridad: 0.2902\n",
            "indice 81198, Palabra: seds, similaridad: 0.2849\n",
            "indice 37181, Palabra: enfant, similaridad: 0.2694\n",
            "indice 38691, Palabra: exploration, similaridad: 0.2398\n",
            "====================================================================================================\n",
            "\n",
            "Palabra original: politics (índice 72031)\n",
            "5 palabras más similares:\n",
            "indice 48657, Palabra: iftccu, similaridad: 0.3048\n",
            "indice 23326, Palabra: bmwmoa, similaridad: 0.2606\n",
            "indice 46323, Palabra: hesh, similaridad: 0.2556\n",
            "indice 39493, Palabra: fascism, similaridad: 0.2482\n",
            "indice 55532, Palabra: lapse, similaridad: 0.2292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para 'computer', las asociaciones con términos como 'decwriter' (0.1579) y 'deluged' (0.1531) reflejan contextos técnicos de hardware y sobrecarga informativa, coherentes con categorías computacionales. 'God' muestra fuertes vínculos religiosos con 'jesus' (0.2806), 'bible' (0.2764) y 'christ' (0.2668), validando clusters temáticos en debates teológicos. 'Car' se relaciona lógicamente con 'cars' (0.1898), 'dealer' (0.1732) y 'civic' (0.1713), capturando temas automovilísticos. 'Space' destaca conexiones espaciales con 'nasa' (0.3279), 'shuttle' (0.2902) y 'seds' (0.2849), alineadas con exploración científica. Finalmente, 'politics' se asocia con 'iftccu' (0.3048), 'bmwmoa' (0.2606) y 'fascism' (0.2482), sugiriendo ideologías y grupos, aunque algunos acrónimos indican especificidad del dataset. En general, esta aproximación demuestra cómo TF-IDF en matrices transpuestas revela co-ocurrencias semánticas."
      ],
      "metadata": {
        "id": "RwhZjCPmqs4n"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3hirpeJeMMa"
      },
      "source": [
        "\n",
        "**3**. Entrenar modelos de clasificación Naïve Bayes para maximizar el desempeño de clasificación\n",
        "(f1-score macro) en el conjunto de datos de test. Considerar cambiar parámteros\n",
        "de instanciación del vectorizador y los modelos y probar modelos de Naïve Bayes Multinomial\n",
        "y ComplementNB."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inicializo variables para guardar la mejor puntuación F1, el mejor modelo y los mejores parámetros del vectorizador\n",
        "mejor_f1 = 0\n",
        "mejor_modelo = None\n",
        "mejor_vect_params = None\n",
        "\n",
        "# defino una lista de configuraciones a probar para TfidfVectorizer\n",
        "# cada diccionario contiene: max_df (umbral para eliminar términos muy frecuentes),\n",
        "# min_df (mínimo de documentos en los que aparece un término para conservarlo) y ngram_range (n-gramas a considerar)\n",
        "configuracion_vector = [\n",
        "    {'max_df': 0.95, 'min_df': 1, 'ngram_range': (1, 1)},  # configuración base: unigramas, conserva términos raros\n",
        "    {'max_df': 0.8,  'min_df': 2, 'ngram_range': (1, 2)},  # incluir bigramas y filtrar términos que aparecen <2 docs\n",
        "    {'max_df': 0.9,  'min_df': 3, 'ngram_range': (1, 1)},  # unigramas con min_df más alto para eliminar raros\n",
        "    {'max_df': 0.95, 'min_df': 1, 'ngram_range': (1, 3)}   # permitir hasta trigramas (mayor dimensionalidad)\n",
        "]\n",
        "\n",
        "# preparo la lista de modelos Naive Bayes a evaluar con distintos valores de suavizado (alpha)\n",
        "# MultinomialNB suele funcionar bien con conteos/TF-IDF; ComplementNB es robusto ante desbalance\n",
        "modelos = [\n",
        "    MultinomialNB(alpha=1.0),  # suavizado Laplace por defecto\n",
        "    MultinomialNB(alpha=0.5),  # menos suavizado (puede ajustar sesgo/varianza)\n",
        "    ComplementNB(alpha=1.0),   # variante para correcciones en clases desbalanceadas\n",
        "    ComplementNB(alpha=0.5)    # misma variante con menor suavizado\n",
        "]\n",
        "\n",
        "# itero sobre cada configuración del vectorizador\n",
        "for vect_params in configuracion_vector:\n",
        "    # instancio el TfidfVectorizer con los parámetros actuales\n",
        "    tfidfvect_opt = TfidfVectorizer(**vect_params)\n",
        "    # ajusto el vectorizador con los textos de entrenamiento y transformo entrenamiento\n",
        "    X_train_opt = tfidfvect_opt.fit_transform(train_group.data)\n",
        "    # transformo el conjunto de prueba con el mismo vectorizador (sin volver a ajustar)\n",
        "    X_test_opt = tfidfvect_opt.transform(test_group.data)\n",
        "\n",
        "    # itero sobre cada modelo definido\n",
        "    for modelo in modelos:\n",
        "        # ajusto el modelo con la matriz TF-IDF optimizada y las etiquetas de entrenamiento\n",
        "        modelo.fit(X_train_opt, y_train)\n",
        "        # predecir etiquetas sobre el conjunto de prueba\n",
        "        y_pred = modelo.predict(X_test_opt)\n",
        "        # calculo la métrica F1 macro para evaluar el desempeño promedio entre clases\n",
        "        f1 = f1_score(y_test, y_pred, average='macro')\n",
        "        # imprimo la configuración y el F1 obtenido para monitorizar resultados\n",
        "        print(f\"Config vect: {vect_params}, Model: {type(modelo).__name__} (alpha={modelo.alpha}), F1-macro: {f1:.4f}\")\n",
        "\n",
        "        # si la F1 actual supera la mejor encontrada, actualizo las variables que guardan el mejor resultado\n",
        "        if f1 > mejor_f1:\n",
        "            mejor_f1 = f1\n",
        "            mejor_modelo = modelo\n",
        "            mejor_vect_params = vect_params\n",
        "\n",
        "# una vez probadas todas las combinaciones, muestro la mejor puntuación y sus parámetros asociados\n",
        "print(f\"\\nMejor F1-macro: {mejor_f1:.4f}\")\n",
        "print(\"Mejores parametros para vectorizador :\", mejor_vect_params)\n",
        "print(\"Mejor modelo:\", mejor_modelo)"
      ],
      "metadata": {
        "id": "HLqhJ699XMGv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bddbbc31-fe1c-4182-e869-dae71e504b24"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config vect: {'max_df': 0.95, 'min_df': 1, 'ngram_range': (1, 1)}, Model: MultinomialNB (alpha=1.0), F1-macro: 0.5854\n",
            "Config vect: {'max_df': 0.95, 'min_df': 1, 'ngram_range': (1, 1)}, Model: MultinomialNB (alpha=0.5), F1-macro: 0.6153\n",
            "Config vect: {'max_df': 0.95, 'min_df': 1, 'ngram_range': (1, 1)}, Model: ComplementNB (alpha=1.0), F1-macro: 0.6930\n",
            "Config vect: {'max_df': 0.95, 'min_df': 1, 'ngram_range': (1, 1)}, Model: ComplementNB (alpha=0.5), F1-macro: 0.6961\n",
            "Config vect: {'max_df': 0.8, 'min_df': 2, 'ngram_range': (1, 2)}, Model: MultinomialNB (alpha=1.0), F1-macro: 0.5703\n",
            "Config vect: {'max_df': 0.8, 'min_df': 2, 'ngram_range': (1, 2)}, Model: MultinomialNB (alpha=0.5), F1-macro: 0.5988\n",
            "Config vect: {'max_df': 0.8, 'min_df': 2, 'ngram_range': (1, 2)}, Model: ComplementNB (alpha=1.0), F1-macro: 0.6878\n",
            "Config vect: {'max_df': 0.8, 'min_df': 2, 'ngram_range': (1, 2)}, Model: ComplementNB (alpha=0.5), F1-macro: 0.6967\n",
            "Config vect: {'max_df': 0.9, 'min_df': 3, 'ngram_range': (1, 1)}, Model: MultinomialNB (alpha=1.0), F1-macro: 0.6044\n",
            "Config vect: {'max_df': 0.9, 'min_df': 3, 'ngram_range': (1, 1)}, Model: MultinomialNB (alpha=0.5), F1-macro: 0.6342\n",
            "Config vect: {'max_df': 0.9, 'min_df': 3, 'ngram_range': (1, 1)}, Model: ComplementNB (alpha=1.0), F1-macro: 0.6909\n",
            "Config vect: {'max_df': 0.9, 'min_df': 3, 'ngram_range': (1, 1)}, Model: ComplementNB (alpha=0.5), F1-macro: 0.6930\n",
            "Config vect: {'max_df': 0.95, 'min_df': 1, 'ngram_range': (1, 3)}, Model: MultinomialNB (alpha=1.0), F1-macro: 0.5210\n",
            "Config vect: {'max_df': 0.95, 'min_df': 1, 'ngram_range': (1, 3)}, Model: MultinomialNB (alpha=0.5), F1-macro: 0.5521\n",
            "Config vect: {'max_df': 0.95, 'min_df': 1, 'ngram_range': (1, 3)}, Model: ComplementNB (alpha=1.0), F1-macro: 0.6712\n",
            "Config vect: {'max_df': 0.95, 'min_df': 1, 'ngram_range': (1, 3)}, Model: ComplementNB (alpha=0.5), F1-macro: 0.6790\n",
            "\n",
            "Mejor F1-macro: 0.6967\n",
            "Mejores parametros para vectorizador : {'max_df': 0.8, 'min_df': 2, 'ngram_range': (1, 2)}\n",
            "Mejor modelo: ComplementNB(alpha=0.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probe cuatro configuraciones de vectorización y cuatro variantes de modelos, lo cual resulta en 16 combinaciones, los resultados muestran que ComplementNB supera consistentemente a MultinomialNB, especialmente con alpha=0.5, al manejar mejor desbalances de clases, la mejor configuración fue max_df=0.8, min_df=2 y ngram_range=(1,2) con ComplementNB(alpha=0.5), alcanzando un F1-macro de 0.6967, mejorando sobre la base (0.5854) gracias a la inclusión de bigramas para capturar contextos y filtrado de términos raros/frecuentes para reducir ruido, por el contrario las configuraciones con trigramas empeoraron el desempeño por mayor dimensionalidad y posible sobreajuste, esto tambien demuestra la importancia de tuning de los hiperparámetros en tareas de clasificación de texto, donde ComplementNB es robusto para datasets multiclasse como este, sugiriendo potenciales mejoras con técnicas adicionales como stemming o cross-validation para mayor generalización."
      ],
      "metadata": {
        "id": "FJjmc1cL-eyF"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}